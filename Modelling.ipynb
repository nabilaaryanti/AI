{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/DEBBY ROBIYANTI/AI/NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLP_Models import TextMining as tm\n",
    "from NLP_Models import CleanText as ct\n",
    "from NLP_Models import modelling as mdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.externals import joblib\n",
    "from sklearn.model_selection import learning_curve\n",
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFinal = pd.read_json('./NLP_Models/data/dataFinalClean.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'date', 'time', 'user_id', 'username', 'name', 'text',\n",
       "       'mentions', 'urls', 'photos', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'hashtags', 'link', 'retweet', 'quote_url', 'near',\n",
       "       'geo', 'source', 'user_rt_id', 'user_rt', 'retweet_id', 'reply_to',\n",
       "       'retweet_date', 'Label', 'cleaned_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFinal.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFinal = dataFinal[['text', 'cleaned_text', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@taufik06644475 @tijabar nah ini tolol yg bole...</td>\n",
       "      <td>tolol berangkat haji negara negara mayoritas n...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biar setan, kadrun, politikus busuk &amp;amp; peng...</td>\n",
       "      <td>setan kadrun politikus busuk tolol nkri lari b...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@dahlia93362963 @abu_ar_rayyan @sukurwong @neg...</td>\n",
       "      <td>bipang year tolol permanen ngeyel karakter bip...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòÇ bipang of the year udah tolol permanen ngeye...</td>\n",
       "      <td>bipang year tolol permanen ngeyel viralin bodo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@goblokkadrun @herlin_673yp @ari3pras @ferdina...</td>\n",
       "      <td>makan bipang ambawang cebong goblok tolol</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812</th>\n",
       "      <td>seru banget gangguin mirae sama jyubi pake gif üòèüòè</td>\n",
       "      <td>seru banget gangguin mirae jyubi pakai gif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14813</th>\n",
       "      <td>sayang banget yaa padahal 2 episode terakhir i...</td>\n",
       "      <td>sayang banget episode bagus banget anti klimas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14814</th>\n",
       "      <td>@dhewi_dhewi @amarfjkt48 ayoo kakkk vc ama fio...</td>\n",
       "      <td>kakk fiony seru banget anaknya wkwkw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14815</th>\n",
       "      <td>@ffarliani tadi aku tanya bayu, katanya ngga p...</td>\n",
       "      <td>bayu nama seru banget</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14816</th>\n",
       "      <td>makasih minn seru banget malming inii üò≠üò≠  #day...</td>\n",
       "      <td>makasih minn seru banget malming inii daysixti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14817 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      @taufik06644475 @tijabar nah ini tolol yg bole...   \n",
       "1      biar setan, kadrun, politikus busuk &amp; peng...   \n",
       "2      @dahlia93362963 @abu_ar_rayyan @sukurwong @neg...   \n",
       "3      üòÇ bipang of the year udah tolol permanen ngeye...   \n",
       "4      @goblokkadrun @herlin_673yp @ari3pras @ferdina...   \n",
       "...                                                  ...   \n",
       "14812  seru banget gangguin mirae sama jyubi pake gif üòèüòè   \n",
       "14813  sayang banget yaa padahal 2 episode terakhir i...   \n",
       "14814  @dhewi_dhewi @amarfjkt48 ayoo kakkk vc ama fio...   \n",
       "14815  @ffarliani tadi aku tanya bayu, katanya ngga p...   \n",
       "14816  makasih minn seru banget malming inii üò≠üò≠  #day...   \n",
       "\n",
       "                                            cleaned_text  Label  \n",
       "0      tolol berangkat haji negara negara mayoritas n...     -1  \n",
       "1      setan kadrun politikus busuk tolol nkri lari b...     -1  \n",
       "2      bipang year tolol permanen ngeyel karakter bip...     -1  \n",
       "3      bipang year tolol permanen ngeyel viralin bodo...     -1  \n",
       "4              makan bipang ambawang cebong goblok tolol     -1  \n",
       "...                                                  ...    ...  \n",
       "14812         seru banget gangguin mirae jyubi pakai gif      1  \n",
       "14813  sayang banget episode bagus banget anti klimas...      1  \n",
       "14814               kakk fiony seru banget anaknya wkwkw      1  \n",
       "14815                              bayu nama seru banget      1  \n",
       "14816  makasih minn seru banget malming inii daysixti...      1  \n",
       "\n",
       "[14817 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ket. label = \n",
    "- hate speech = -1\n",
    "- non hate speech = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    8117\n",
       " 1    6700\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFinal.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFinal.to_json('./NLP_Models/data/uas_no1.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc model terbaik adalah: 0.9999972449614938\n",
      "roc_auc model estimator terbaik adalah: 0.9983130904183536\n",
      "Parameter terbaik adalah: {'svc__C': 0.1}\n",
      "Rataan roc_auc model tiap fold adalah: 0.9999936199733787\n"
     ]
    }
   ],
   "source": [
    "modelSVC = mdg.modelling(data = dataFinal, modelname= '202106',\\\n",
    "                         crossval = False,  termfrequency = False, \\\n",
    "                             n_fold = 3, kernel = 'linear', n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8106,   11],\n",
       "       [   2, 6698]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdg.confusionMatrix(modelSVC[0], dataFinal.cleaned_text.values, dataFinal.Label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.9999976647500455,\n",
       " 'f1': 0.9990305019017078,\n",
       " 'acc': 0.9991226294121617,\n",
       " 'precision': 0.9983604113876882,\n",
       " 'recall': 0.9997014925373134}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdg.report_results(modelSVC[0], dataFinal.cleaned_text.values, dataFinal.Label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uji Coba Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLP_Models import deepHateSpeechDetection as dhsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@azizprasetyo4 @haikal_hassan cebong makin dungu, dan tolol akut otaknya. cebong akut'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFinal.text.iloc[3434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataFinal.text.iloc[3434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_pred': {'hate': 99.99998999999902, 'nonhate': 1.0000000994736041e-05},\n",
       " 'final_result': 'hate',\n",
       " 'confidence': 100.0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhsd.hateSpeechPredict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lagi dibangku sekolah ingat betul tulisan tanganku ttg doa mau keluar negeri, mau ini mau itu dll buanyak di dll.buku diaryku mau naik kuda pun ada ku tulis di sana.. ahhhha semangat sembari menunggu takdir yg allah janjikan dan itu terkabul setelah kian tahun..'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFinal.text.iloc[11344]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataFinal.text.iloc[5834]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_pred': {'hate': 99.9999878785867, 'nonhate': 1.2121413299109607e-05},\n",
       " 'final_result': 'hate',\n",
       " 'confidence': 100.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhsd.hateSpeechPredict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='bismillah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_pred': {'hate': 39.75343460413779, 'nonhate': 60.24656539586219},\n",
       " 'final_result': 'nonhate',\n",
       " 'confidence': 60.247}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhsd.hateSpeechPredict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'sebelum jadi anak kost yang kemana mana pake hoodie merch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_pred': {'hate': 39.887085575418, 'nonhate': 60.112914424582},\n",
       " 'final_result': 'nonhate',\n",
       " 'confidence': 60.113}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhsd.hateSpeechPredict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
